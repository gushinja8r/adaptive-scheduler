{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run learners in job scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the learners\n",
    "\n",
    "We need the following variables:\n",
    "* `learners` a list of learners\n",
    "* `fnames` a list of file names, one for each learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile learners_file.py\n",
    "\n",
    "import adaptive\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def h(x, offset=0):\n",
    "    import numpy as np\n",
    "    import random\n",
    "\n",
    "    for _ in range(10):  # Burn some CPU time just because\n",
    "        np.linalg.eig(np.random.rand(1000, 1000))\n",
    "\n",
    "    a = 0.01\n",
    "    return x + a ** 2 / (a ** 2 + (x - offset) ** 2)\n",
    "\n",
    "\n",
    "offset = [i / 20 - 0.5 for i in range(20)]\n",
    "\n",
    "combos = adaptive.utils.named_product(offset=offset)\n",
    "\n",
    "learners = []\n",
    "fnames = []\n",
    "\n",
    "for i, combo in enumerate(combos):\n",
    "    f = partial(h, offset=combo[\"offset\"])\n",
    "    learner = adaptive.Learner1D(f, bounds=(-1, 1))\n",
    "    fnames.append(f\"data/{combo}\")\n",
    "    learners.append(learner)\n",
    "\n",
    "learner = adaptive.BalancingLearner(learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the previous code block and plot the learners\n",
    "from learners_file import *\n",
    "adaptive.notebook_extension()\n",
    "learner.load(fnames)\n",
    "learner.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Python script that is run on the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to use the headnode's address in the next cell\n",
    "from adaptive_scheduler import server_support\n",
    "server_support.get_allowed_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run_learner.py\n",
    "\n",
    "import adaptive\n",
    "from adaptive_scheduler import client_support\n",
    "from mpi4py.futures import MPIPoolExecutor\n",
    "\n",
    "from learners_file import learners, fnames\n",
    "\n",
    "url = \"tcp://10.75.0.5:57101\"\n",
    "learner, fname = client_support.get_learner(url, learners, fnames)\n",
    "learner.load(fname)\n",
    "runner = adaptive.Runner(\n",
    "    learner, executor=MPIPoolExecutor(), shutdown_executor=True, goal=None\n",
    ")\n",
    "runner.start_periodic_saving(dict(fname=fname), interval=600)\n",
    "client_support.log_info(runner, interval=600)  # log info in the job output script\n",
    "runner.ioloop.run_until_complete(runner.task)  # wait until runner goal reached\n",
    "client_support.is_done(url, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the files that were created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_scheduler import server_support\n",
    "from learners_file import learners, fnames\n",
    "\n",
    "db_fname = 'running.tinydb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_support.create_empty_db(db_fname, fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the running learners in the database\n",
    "All the ones that are `None` are still `PENDING`, reached their goal, or are not scheduled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_support.get_database(db_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the job scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from adaptive_scheduler import server_support, slurm\n",
    "from learners_file import learners, fnames\n",
    "\n",
    "# create unique names for the jobs\n",
    "job_names = [f\"test-job-{i}\" for i in range(len(learners))]\n",
    "\n",
    "# start the \"job manager\" and the \"database manager\"\n",
    "database_task = server_support.start_database_manager(\"tcp://10.75.0.5:57101\", db_fname)\n",
    "\n",
    "job_task = server_support.start_job_manager(\n",
    "    job_names,\n",
    "    db_fname=db_fname,\n",
    "    cores=1,\n",
    "    interval=60,\n",
    "    run_script=\"run_learner.py\",  # optional\n",
    "    python_executable=\"~/miniconda3/envs/py37_min/bin/python\",  # optional\n",
    "    job_script_function=slurm.make_job_script,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_task.print_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_task.print_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to STOP managing the database and jobs\n",
    "job_task.cancel(), database_task.cancel()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
