{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run learners in job scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the learners\n",
    "\n",
    "We need the following variables:\n",
    "* `learners` a list of learners\n",
    "* `combos` a list of dicts of parameters that describe each learner\n",
    "* `fnames` a list of filenames of each learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile _learners.py\n",
    "\n",
    "import adaptive\n",
    "from functools import partial\n",
    "\n",
    "import funcs\n",
    "\n",
    "syst_pars = dict(a=4, L=40, r=20, shape=\"square\", dim=3)\n",
    "\n",
    "params = dict(g=50, mu=100, B_y=0, B_x=0, **funcs.constants_InAs)\n",
    "\n",
    "Ls = [1000, 2000, 3000, 5000, 10000]\n",
    "l_Rs = [200] #np.geomspace(30, 1000, 10).tolist() + [np.inf]\n",
    "l_es = [20, 50, 100, 200, 300, 500]\n",
    "rs = [25]\n",
    "\n",
    "combos = adaptive.utils.named_product(l_e=l_es, L=Ls, r=rs, l_R=l_Rs)\n",
    "\n",
    "learners = []\n",
    "fnames = []\n",
    "folder = \"data/q_phi_scaling_square_wire_new/\"\n",
    "for combo in combos:\n",
    "    f = partial(\n",
    "        funcs.conductance_1D,\n",
    "        x_name='B_z',\n",
    "        value_dict=combo,\n",
    "        syst_pars=syst_pars,\n",
    "        params=params,\n",
    "    )\n",
    "    learner = adaptive.AverageLearner1D(f, bounds=(0, 0.25))\n",
    "    learner.average_priority = 1\n",
    "    learner.min_seeds_per_point = 20\n",
    "    fnames.append(f\"{folder}_{combo}\")\n",
    "    learners.append(learner)\n",
    "\n",
    "learner = adaptive.BalancingLearner(learners, strategy='cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the previous code block and plot the learners\n",
    "from _learners import *\n",
    "adaptive.notebook_extension()\n",
    "learner.load(fnames)\n",
    "learner.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Python script that is being run in the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to use the headnode's IP below.\n",
    "import socket\n",
    "import zmq.ssh\n",
    "ip = socket.gethostbyname(socket.gethostname())\n",
    "port = zmq.ssh.tunnel.select_random_ports(1)[0]\n",
    "print(f'tcp://{ip}:{port}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run_learner.py\n",
    "\n",
    "import adaptive\n",
    "from mpi4py.futures import MPIPoolExecutor\n",
    "\n",
    "from adaptive.scheduler import client_support\n",
    "\n",
    "url = \"tcp://10.76.0.5:57681\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    learner, fname = client_support.get_learner(url)\n",
    "    learner.load(fname)\n",
    "    ex = MPIPoolExecutor()\n",
    "    runner = adaptive.Runner(\n",
    "        learner,\n",
    "        executor=ex,\n",
    "        goal=None,\n",
    "        shutdown_executor=True,\n",
    "        ioloop=None,\n",
    "        retries=10,\n",
    "        raise_if_retries_exceeded=False,\n",
    "    )\n",
    "    runner.start_periodic_saving(dict(fname=fname), interval=600)\n",
    "    runner.ioloop.run_until_complete(runner.task)  # wait until runner goal reached\n",
    "    client_support.is_done(url, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the files that were created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from importlib import reload\n",
    "\n",
    "from adaptive.scheduler import server_support\n",
    "from pprint import pprint\n",
    "from tinydb import TinyDB\n",
    "\n",
    "_learners, run_learner\n",
    "\n",
    "reload(_learners)\n",
    "reload(run_learner)\n",
    "\n",
    "db_fname = 'running.tinydb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new database\n",
    "server_support.create_empty_db(db_fname, _learners.fnames, _learners.combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the running learners\n",
    "All the onces that are `None` are still `PENDING` or are not scheduled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with TinyDB(db_fname) as db:\n",
    "    pprint(db.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the job scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some unique names for the jobs\n",
    "job_names = [f\"WAL-{i}\" for i in range(len(_learners.learners))]\n",
    "\n",
    "ioloop = asyncio.get_event_loop()\n",
    "\n",
    "database_task = ioloop.create_task(\n",
    "    server_support.manage_database(\"tcp://*:57681\", db_fname)\n",
    ")\n",
    "\n",
    "job_task = ioloop.create_task(\n",
    "    server_support.manage_jobs(job_names, db_fname, ioloop, cores=50*8, interval=60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_task.cancel(), database_task.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_task.print_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_task.print_stack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
